{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02074e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "soft triple loss其实就是把每一个class分成了k个center，在这里我们设k=10，通过将data分类到centers上而不是class上以增强分类的准确率，\n",
    "soft triple的代码把训练分成两部分，一部分是backbone的神经网络，另一部分是一个全连接（dim，cN*K），\n",
    "这里dim是backbone出来的数据维数（embedding的维度），cN是class number， K是center数量。\n",
    "\n",
    "源代码里面backbone的训练用的是lr=0.0001的adam，而fc的训练用的是lr=0.01的adam，这里论文如果没有详细解释的话我个人认为有特意调参的痕迹\n",
    "\n",
    "改了baseline+soft的网络，用soft triple论文的参数0.0001/0.01\n",
    "参数的设置在io_utils中，当然你也可以用 --modellr和--centerlr修改\n",
    "使用soft triple 的命令是 --method baseline_soft\n",
    "\n",
    "例如\n",
    "!python ./train.py --dataset CUB --model Conv4 --method baseline_soft --train_aug\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfe907",
   "metadata": {},
   "source": [
    "# io_utils 参数更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(script):\n",
    "    parser.add_argument('--K'           , default=10,           help='num of centers for each class')\n",
    "    parser.add_argument('--la'          , default=20, type=float,  help='lambda of soft triple')\n",
    "    parser.add_argument('--gamma'       , default=0.1, type=float, help='gamma of soft triple')\n",
    "    parser.add_argument('--tau'         , default=0.2, type=float,  help='tau of soft triple')\n",
    "    parser.add_argument('--margin'      , default=0.01, type=float, help='margin of soft triple')\n",
    "    parser.add_argument('--modellr', default=0.0001, type=float, help='model learning rate of soft triple')\n",
    "    parser.add_argument('--centerlr', default=0.01, type=float, help='center learning rate of soft triple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c691d",
   "metadata": {},
   "source": [
    "# 文档更新\n",
    "\n",
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baselinetrain_softtriple import BaselineTrainSoft\n",
    "\n",
    "if params.method == 'baseline_soft':\n",
    "    optimizer = torch.optim.Adam([{\"params\": model.feature.parameters(), \"lr\": params.modellr},\n",
    "                                      {\"params\": model.fc, \"lr\": params.centerlr}]) #line 28-30\n",
    "\n",
    "elif params.method =='baseline_soft'\n",
    "    model           = BaselineTrainSoft( model_dict[params.model], la = params.la, gamma = params.gamma, \n",
    "                                        tau=params.tau, margin=params.margin, K=params.K, cN=params.num_classes)# line115-116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66369143",
   "metadata": {},
   "source": [
    "## save_features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baselinetrain_softtriple import BaselineTrainSoft #line 13\n",
    "\n",
    "if not params.method in ['baseline', 'baseline++', 'baseline_soft'] : #line77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf157495",
   "metadata": {},
   "source": [
    "## methods.baselinetrain_softtriple.py\n",
    "整个文件。结合baselinetrain.py以及softtriple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ebc06",
   "metadata": {},
   "source": [
    "## baselinefinetune.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea8a46",
   "metadata": {},
   "source": [
    "增加了新的class BaselineFinetune_soft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38271e0c",
   "metadata": {},
   "source": [
    "## baselinefinetune.py 调参和对照实验提示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65ea5b",
   "metadata": {},
   "source": [
    "train stage 是固定的，backbone 接softtriple模型。参数可用在train的时候通过parser调整。\n",
    "finetune stage的参数不通过paser调整（因为写起来麻烦），调整请在class BaselineFinetune_soft的__init__中改动\n",
    "\n",
    "\n",
    "fine tune提供3种测试方案\n",
    "\n",
    "#### 1.如果探寻Softtriple方法的准确率，则只需改动参数即可 （纯softtriple方法）\n",
    "\n",
    "#### 2.使用linear.clf代替center连接（嫁接classifier+softtriple方法）\n",
    "uncomment line 90,92 或 94,96,\n",
    "\n",
    "uncomment line 137-138, 149-150\n",
    "\n",
    "comment line 134-136, 146-148\n",
    "\n",
    "uncomment line 99-100\n",
    "\n",
    "comment line 102\n",
    "\n",
    "#### 3.完全使用baseline和baseline++的scores\n",
    "uncomment line 99-100\n",
    "\n",
    "comment line 102\n",
    "\n",
    "uncomment line 110-122\n",
    "\n",
    "comment line 125-153\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c5947",
   "metadata": {},
   "source": [
    "我都测试了一下，基本上就是65-66的准确率了， 三种方案结果都差不多。Softtriple应该是最贴近baseline model的，因为fewshot中本来class就很少，在一个class中K值取大了反而没什么意义，而当K值越趋近于1，Softtriple就越趋近于softmax了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbd2c7",
   "metadata": {},
   "source": [
    "## 增加了decay rate\n",
    "但是两篇论文epoch差太远了，所以并没用使用decay rate. 或许可以尝试吧。\n",
    "\n",
    "train.py， 25-27,45-46\n",
    "\n",
    "其次model_lr也很小，只有0.0001,均参考自softtriple论文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e72e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
